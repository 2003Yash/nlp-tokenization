{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMpIaE/cC6odPnjBaHXvz5A",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/2003Yash/nlp-tokenization/blob/main/NLP_Tokenize%2C_Stemming_and_Lemmatize.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0vZTz3ELytjQ"
      },
      "outputs": [],
      "source": [
        "corpus = \"\"\" Hello, welcome this is Yaswanth your new president of the country.\n",
        "             Thanks for your vote and i will make sure you have not wasted your vote and time.\n",
        "             Thanks again for your vote.\n",
        " \"\"\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "corpus"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "-VDAJkJBzsTl",
        "outputId": "cbd78946-697e-4580-e24b-c3aeb8f5cc72"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "' Hello, welcome this is Yaswanth your new president of the country.\\n             Thanks for your vote and i will make sure you have not wasted your vote and time.\\n             Thanks again for your vote.\\n '"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(corpus)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g1IZKTjfzxYl",
        "outputId": "fd59ac67-70a9-429a-a28f-2a5f335c8000"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Hello, welcome this is Yaswanth your new president of the country.\n",
            "             Thanks for your vote and i will make sure you have not wasted your vote and time.\n",
            "             Thanks again for your vote.\n",
            " \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**SENTENCE TOKENIZER**"
      ],
      "metadata": {
        "id": "4CSNNQ3z1wIC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Converting into sentence tokens out of corpus/paragraph\n",
        "\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "\n",
        "from nltk.tokenize import sent_tokenize\n",
        "sent_tokenize(corpus)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3kzKn-VGz1M3",
        "outputId": "7c00d663-4f43-4fbd-f9a4-f33dac3f7d88"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[' Hello, welcome this is Yaswanth your new president of the country.',\n",
              " 'Thanks for your vote and i will make sure you have not wasted your vote and time.',\n",
              " 'Thanks again for your vote.']"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "documents = sent_tokenize(corpus)\n",
        "#and the sent tokenize will output list\n",
        "type(documents)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mGpCxmf80Og4",
        "outputId": "707ef8d8-3081-42da-e9ed-2c46d74435ae"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "list"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for sentence in documents:\n",
        "  print(sentence)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zAKf1MxU0dIV",
        "outputId": "23aaf2fa-dbe0-4d10-fb8c-93ed86a12e21"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Hello, welcome this is Yaswanth your new president of the country.\n",
            "Thanks for your vote and i will make sure you have not wasted your vote and time.\n",
            "Thanks again for your vote.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**WORD TOKENIZER**"
      ],
      "metadata": {
        "id": "-H_DqVxt13A2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#word tokenize\n",
        "\n",
        "from nltk.tokenize import word_tokenize\n",
        "word_tokenize(corpus)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v9hpIYCU0kDL",
        "outputId": "031214d2-ba4a-4bf5-f57c-b0ae659e2452"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Hello',\n",
              " ',',\n",
              " 'welcome',\n",
              " 'this',\n",
              " 'is',\n",
              " 'Yaswanth',\n",
              " 'your',\n",
              " 'new',\n",
              " 'president',\n",
              " 'of',\n",
              " 'the',\n",
              " 'country',\n",
              " '.',\n",
              " 'Thanks',\n",
              " 'for',\n",
              " 'your',\n",
              " 'vote',\n",
              " 'and',\n",
              " 'i',\n",
              " 'will',\n",
              " 'make',\n",
              " 'sure',\n",
              " 'you',\n",
              " 'have',\n",
              " 'not',\n",
              " 'wasted',\n",
              " 'your',\n",
              " 'vote',\n",
              " 'and',\n",
              " 'time',\n",
              " '.',\n",
              " 'Thanks',\n",
              " 'again',\n",
              " 'for',\n",
              " 'your',\n",
              " 'vote',\n",
              " '.']"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for sentence in documents:\n",
        "  print(word_tokenize(sentence))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1yB9M-C40ulk",
        "outputId": "15c39e86-8f85-4b64-ccdc-52ebdd52b849"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Hello', ',', 'welcome', 'this', 'is', 'Yaswanth', 'your', 'new', 'president', 'of', 'the', 'country', '.']\n",
            "['Thanks', 'for', 'your', 'vote', 'and', 'i', 'will', 'make', 'sure', 'you', 'have', 'not', 'wasted', 'your', 'vote', 'and', 'time', '.']\n",
            "['Thanks', 'again', 'for', 'your', 'vote', '.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**TREEBANK WORD TOKENIZER**"
      ],
      "metadata": {
        "id": "bCAECsut1_jr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.tokenize import TreebankWordTokenizer #except last word all other . aren't seperate\n",
        "tokenizer = TreebankWordTokenizer()\n",
        "tokenizer.tokenize(corpus)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f5GdHDeF0z3M",
        "outputId": "177175da-bdaf-473f-d5f4-d43a051362a3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Hello',\n",
              " ',',\n",
              " 'welcome',\n",
              " 'this',\n",
              " 'is',\n",
              " 'Yaswanth',\n",
              " 'your',\n",
              " 'new',\n",
              " 'president',\n",
              " 'of',\n",
              " 'the',\n",
              " 'country.',\n",
              " 'Thanks',\n",
              " 'for',\n",
              " 'your',\n",
              " 'vote',\n",
              " 'and',\n",
              " 'i',\n",
              " 'will',\n",
              " 'make',\n",
              " 'sure',\n",
              " 'you',\n",
              " 'have',\n",
              " 'not',\n",
              " 'wasted',\n",
              " 'your',\n",
              " 'vote',\n",
              " 'and',\n",
              " 'time.',\n",
              " 'Thanks',\n",
              " 'again',\n",
              " 'for',\n",
              " 'your',\n",
              " 'vote',\n",
              " '.']"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**WORD PUNCT TOKENIZER**"
      ],
      "metadata": {
        "id": "rTUlfnPr2Dlt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk import wordpunct_tokenize\n",
        "wordpunct_tokenize(corpus) #' is considered as a seperatre word"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LKx5jw5R1Foj",
        "outputId": "bbf8353a-d2c3-4ca9-a0e9-83fabfdd63a3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Hello',\n",
              " ',',\n",
              " 'welcome',\n",
              " 'this',\n",
              " 'is',\n",
              " 'Yaswanth',\n",
              " 'your',\n",
              " 'new',\n",
              " 'president',\n",
              " 'of',\n",
              " 'the',\n",
              " 'country',\n",
              " '.',\n",
              " 'Thanks',\n",
              " 'for',\n",
              " 'your',\n",
              " 'vote',\n",
              " 'and',\n",
              " 'i',\n",
              " 'will',\n",
              " 'make',\n",
              " 'sure',\n",
              " 'you',\n",
              " 'have',\n",
              " 'not',\n",
              " 'wasted',\n",
              " 'your',\n",
              " 'vote',\n",
              " 'and',\n",
              " 'time',\n",
              " '.',\n",
              " 'Thanks',\n",
              " 'again',\n",
              " 'for',\n",
              " 'your',\n",
              " 'vote',\n",
              " '.']"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**STEMMING**"
      ],
      "metadata": {
        "id": "ltNoxPq92IIN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "word = [\"eaten\", \"Eats, Writing\", \"Writes\", \"Programming\", \"Programs\", \"History\", \"Finally\", \"Finalized\"]"
      ],
      "metadata": {
        "id": "wjOA9I2W1lWr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**PORTER STEMMER**"
      ],
      "metadata": {
        "id": "9hvLBf3r2paa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.stem import PorterStemmer\n",
        "ps = PorterStemmer()\n",
        "for word in word:\n",
        "  print(word +  \"--->\" + ps.stem(word))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "woECzwIt2rf6",
        "outputId": "faae2df6-c1bb-427e-91d4-c3d939bf8e62"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "eaten--->eaten\n",
            "Eats, Writing--->eats, writ\n",
            "Writes--->write\n",
            "Programming--->program\n",
            "Programs--->program\n",
            "History--->histori\n",
            "Finally--->final\n",
            "Finalized--->final\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ps.stem('congratulations')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "tjDP3HjT2_Xr",
        "outputId": "48a5b4f1-2755-435d-dfb3-b25c9b0feb3d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'congratul'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**REGEX STEMMER**"
      ],
      "metadata": {
        "id": "-Fa292wH35Ps"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.stem import RegexpStemmer\n",
        "rs = RegexpStemmer('ing$|es$|s$', min = 4)\n",
        "rs.stem(\"Doing\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "EhYbJ91D38Rl",
        "outputId": "13b7423a-b6ad-40ed-8aae-ecc33a98566f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Do'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**SNOBALL STEMMER**"
      ],
      "metadata": {
        "id": "J70mSio44rGI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.stem import SnowballStemmer\n",
        "ss = SnowballStemmer('english')\n",
        "for word in word:\n",
        "  print(word +  \"--->\" + ss.stem(word))\n",
        "\n",
        "  #IF OUTPUT IS SOME RANDOM DATA THEN RUN THE WORD CELL FROM ABOVE AND RUN THIS AGAIN"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "26va3gjr3DUQ",
        "outputId": "430cf0de-8d6b-42ef-b645-642d919faeec"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "eaten--->eaten\n",
            "Eats, Writing--->eats, writ\n",
            "Writes--->write\n",
            "Programming--->program\n",
            "Programs--->program\n",
            "History--->histori\n",
            "Finally--->final\n",
            "Finalized--->final\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ps.stem('Fairly')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "XT1Ei3o25KTZ",
        "outputId": "4e049752-b470-4687-a989-211295a8876d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'fairli'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ss.stem('fairly')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "iWAuMLIK5Oc5",
        "outputId": "35ba1152-336a-4192-eaf3-db359b366ea7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'fair'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**LEMMATIZATION**"
      ],
      "metadata": {
        "id": "9pOOgWE-5UgJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('wordnet')\n",
        "\n",
        "\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "for word in word:\n",
        "  print(word +  \"--->\" + lemmatizer.lemmatize(word))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U5nsI4im5Xim",
        "outputId": "744dca7f-d8ad-4e0c-adf8-d9c5c450301c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "eaten--->eaten\n",
            "Eats, Writing--->Eats, Writing\n",
            "Writes--->Writes\n",
            "Programming--->Programming\n",
            "Programs--->Programs\n",
            "History--->History\n",
            "Finally--->Finally\n",
            "Finalized--->Finalized\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ]
        }
      ]
    }
  ]
}